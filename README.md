# Abnormal Traffic Detection using Double Deep Q-Network (DDQN)

This project applies **Reinforcement Learning**â€”specifically, a **Double Deep Q-Network (DDQN)**â€”to detect abnormal (malicious) traffic within network data. It leverages a custom OpenAI Gym environment built on top of the **NSL-KDD** dataset, a standard benchmark in intrusion detection systems (IDS).

## ğŸ“Œ Overview

- **Dataset**: [NSL-KDD](https://www.unb.ca/cic/datasets/nsl.html)
- **Algorithm**: Double Deep Q-Learning (DDQN)
- **Environment**: Custom Gym Environment simulating network traffic behavior
- **Goal**: Classify each traffic record as normal or abnormal using reinforcement learning

## ğŸš€ Key Features

- Preprocessing pipeline for NSL-KDD data (label encoding, normalization)
- Custom OpenAI Gym environment
- Double DQN with experience replay and target network updates
- Evaluation using accuracy, reward trends, and confusion matrix

## ğŸ§  DDQN Concept

- Uses **two networks**: one to select the action (policy) and one to evaluate it (target)
- Addresses overestimation bias found in standard DQN
- Reinforces learning through rewards based on classification accuracy

## ğŸ—‚ï¸ Files

- `Abnormal_Traffic_Detection_DDQN.ipynb` â€“ Main Colab notebook
- `environment.py` (within the notebook) â€“ Contains custom Gym environment class
- `data` â€“ Loaded programmatically (NSL-KDD train/test datasets)

## ğŸ“ˆ Results

- Agent learns to distinguish between normal and abnormal traffic over episodes
- Rewards per episode increase, indicating improved performance
- Accuracy and confusion matrix show effective classification

## ğŸ”§ Requirements

This runs in **Google Colab**. If running locally, install:

```bash
pip install numpy pandas matplotlib scikit-learn tensorflow keras gym
